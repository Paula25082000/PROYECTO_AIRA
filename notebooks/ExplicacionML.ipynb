{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc762b0",
   "metadata": {},
   "source": [
    "# Explicaci√≥n del An√°lisis de Machine Learning: Clustering de Pa√≠ses\n",
    "\n",
    "Este notebook explica de manera detallada y accesible todo el proceso de Machine Learning aplicado en la **Secci√≥n 6** del EDA para identificar tipolog√≠as de pa√≠ses seg√∫n su implementaci√≥n de IA en salud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b44596f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö √çndice\n",
    "\n",
    "1. [¬øQu√© es el Clustering?](#1-que-es-el-clustering)\n",
    "2. [¬øPor qu√© usar Machine Learning en este proyecto?](#2-por-que-usar-machine-learning)\n",
    "3. [Preparaci√≥n de los Datos](#3-preparacion-de-los-datos)\n",
    "4. [Algoritmo K-means](#4-algoritmo-k-means)\n",
    "5. [Determinaci√≥n del n√∫mero √≥ptimo de clusters](#5-numero-optimo-de-clusters)\n",
    "6. [Reducci√≥n de Dimensionalidad con PCA](#6-reduccion-de-dimensionalidad-pca)\n",
    "7. [Interpretaci√≥n de Resultados](#7-interpretacion-de-resultados)\n",
    "8. [Conclusiones y Aplicaciones](#8-conclusiones-y-aplicaciones)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7aeaaa",
   "metadata": {},
   "source": [
    "## 1. ¬øQu√© es el Clustering?\n",
    "\n",
    "### Concepto B√°sico\n",
    "\n",
    "El **clustering** (agrupamiento) es una t√©cnica de **aprendizaje no supervisado** que consiste en agrupar objetos similares en categor√≠as llamadas \"clusters\" o grupos.\n",
    "\n",
    "### üéØ Analog√≠a Simple\n",
    "\n",
    "Imagina que tienes una caja con frutas mezcladas (manzanas, naranjas, pl√°tanos, fresas). El clustering es como organizar estas frutas en grupos seg√∫n sus caracter√≠sticas (color, tama√±o, forma) **sin que nadie te diga previamente qu√© grupos debes formar**. El algoritmo descubre autom√°ticamente que:\n",
    "- Las manzanas y fresas son rojas y redondeadas ‚Üí Grupo 1\n",
    "- Las naranjas son redondas y naranjas ‚Üí Grupo 2  \n",
    "- Los pl√°tanos son alargados y amarillos ‚Üí Grupo 3\n",
    "\n",
    "### En Nuestro Proyecto\n",
    "\n",
    "En lugar de frutas, tenemos **pa√≠ses** que queremos agrupar seg√∫n sus caracter√≠sticas de:\n",
    "- Estrategia en IA\n",
    "- Regulaci√≥n\n",
    "- Gobernanza de datos\n",
    "- Aplicaciones de IA\n",
    "- Desarrollo de capacidades\n",
    "\n",
    "El objetivo es identificar **tipolog√≠as de pa√≠ses** como:\n",
    "- \"Pa√≠ses l√≠deres en IA\"\n",
    "- \"Pa√≠ses con estrategia pero sin implementaci√≥n\"\n",
    "- \"Pa√≠ses rezagados\"\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ddcdfa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ¬øPor qu√© usar Machine Learning?\n",
    "\n",
    "### El Desaf√≠o\n",
    "\n",
    "Tenemos **53 pa√≠ses** con **75 variables AIRA** cada uno. Esto representa:\n",
    "- 3,975 puntos de datos individuales\n",
    "- Variables categ√≥ricas (YES/NO/UD)\n",
    "- M√∫ltiples dimensiones que analizar simult√°neamente\n",
    "\n",
    "### ‚ùå ¬øPor qu√© NO hacerlo manualmente?\n",
    "\n",
    "1. **Es imposible visualizar 75 dimensiones**: Los humanos solo podemos ver en 2D o 3D\n",
    "2. **Subjetividad**: Cada persona podr√≠a crear grupos diferentes\n",
    "3. **Tiempo**: Analizar manualmente tomar√≠a semanas\n",
    "4. **Patrones ocultos**: Hay relaciones complejas que no son obvias a simple vista\n",
    "\n",
    "### ‚úÖ Ventajas del Machine Learning\n",
    "\n",
    "1. **Objetividad**: El algoritmo usa criterios matem√°ticos consistentes\n",
    "2. **Velocidad**: Procesa miles de datos en segundos\n",
    "3. **Descubrimiento de patrones**: Encuentra relaciones no evidentes\n",
    "4. **Reproducibilidad**: Los resultados son consistentes y verificables\n",
    "\n",
    "### üéì Tipo de Aprendizaje\n",
    "\n",
    "**Aprendizaje No Supervisado**: No hay \"respuestas correctas\" predefinidas. El algoritmo explora los datos y descubre estructuras naturales sin que nadie le diga qu√© buscar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc490b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Preparaci√≥n de los Datos\n",
    "\n",
    "### Paso 1: Reestructuraci√≥n de Datos\n",
    "\n",
    "#### Formato Original (Largo)\n",
    "```\n",
    "| Pa√≠s | Variable | Respuesta |\n",
    "|------|----------|----------|\n",
    "| ESP  | AIRA_1   | YES      |\n",
    "| ESP  | AIRA_2   | NO       |\n",
    "| FRA  | AIRA_1   | YES      |\n",
    "| FRA  | AIRA_2   | UD       |\n",
    "```\n",
    "\n",
    "#### Formato Transformado (Ancho)\n",
    "```\n",
    "| Pa√≠s | AIRA_1 | AIRA_2 | AIRA_3 | ... |\n",
    "|------|--------|--------|--------|-----|\n",
    "| ESP  | YES    | NO     | UD     | ... |\n",
    "| FRA  | YES    | UD     | YES    | ... |\n",
    "```\n",
    "\n",
    "**¬øPor qu√©?** Los algoritmos de ML necesitan una fila por pa√≠s con todas sus caracter√≠sticas.\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 2: Codificaci√≥n de Variables Categ√≥ricas\n",
    "\n",
    "#### El Problema\n",
    "Los algoritmos de ML trabajan con **n√∫meros**, no con palabras. No entienden \"YES\" o \"NO\".\n",
    "\n",
    "#### La Soluci√≥n: Codificaci√≥n Ordinal\n",
    "\n",
    "Transformamos las respuestas en n√∫meros que reflejan el **nivel de implementaci√≥n**:\n",
    "\n",
    "```python\n",
    "YES (Implementado totalmente)        ‚Üí 2\n",
    "UD (En desarrollo / No sabe)         ‚Üí 1  \n",
    "NO (No implementado)                 ‚Üí 0\n",
    "```\n",
    "\n",
    "#### ¬øPor qu√© este mapeo?\n",
    "\n",
    "- **Ordinal**: Los n√∫meros tienen un orden l√≥gico (0 < 1 < 2)\n",
    "- **Interpretable**: Un pa√≠s con m√°s \"2s\" est√° m√°s avanzado\n",
    "- **Matem√°ticamente v√°lido**: Permite calcular promedios y distancias\n",
    "\n",
    "#### Ejemplo\n",
    "```\n",
    "Antes:  ESP ‚Üí [YES, NO, UD, YES, NO]\n",
    "Despu√©s: ESP ‚Üí [2, 0, 1, 2, 0]  \n",
    "Promedio: 1.0 (nivel medio de implementaci√≥n)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Paso 3: Manejo de Valores Faltantes\n",
    "\n",
    "#### El Problema\n",
    "Algunos pa√≠ses no respondieron ciertas preguntas ‚Üí valores vac√≠os (NaN)\n",
    "\n",
    "#### T√©cnica Aplicada: Imputaci√≥n por Mediana\n",
    "\n",
    "**Mediana**: El valor del medio cuando ordenas todos los n√∫meros.\n",
    "\n",
    "Ejemplo:\n",
    "```\n",
    "Variable AIRA_5 en todos los pa√≠ses: [0, 0, 1, 2, 2, ?, 2, 1]\n",
    "Ordenados: [0, 0, 1, 1, 2, 2, 2]\n",
    "Mediana: 1 (valor central)\n",
    "Resultado: [0, 0, 1, 2, 2, 1, 2, 1]\n",
    "```\n",
    "\n",
    "#### ¬øPor qu√© la mediana y no la media?\n",
    "\n",
    "- **Robusta**: No se ve afectada por valores extremos\n",
    "- **Conservadora**: Mantiene el valor m√°s \"t√≠pico\" del grupo\n",
    "- **Apropiada para datos ordinales**: Tiene sentido con escalas 0-1-2\n",
    "\n",
    "---\n",
    "\n",
    "### Resultado de la Preparaci√≥n\n",
    "\n",
    "**Dataset final**:\n",
    "- **53 filas** (pa√≠ses)\n",
    "- **75 columnas** (variables AIRA codificadas)\n",
    "- **Todos valores num√©ricos** (0, 1, o 2)\n",
    "- **Sin valores faltantes**\n",
    "\n",
    "‚úÖ **¬°Listo para aplicar Machine Learning!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70433e7b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Algoritmo K-means\n",
    "\n",
    "### ¬øQu√© es K-means?\n",
    "\n",
    "**K-means** es el algoritmo de clustering m√°s popular. Agrupa datos en **K clusters** minimizando la distancia entre cada punto y el centro de su cluster.\n",
    "\n",
    "### üéØ Analog√≠a del Supermercado\n",
    "\n",
    "Imagina que eres due√±o de una cadena de supermercados y quieres abrir 3 tiendas en una ciudad:\n",
    "\n",
    "1. **K = 3**: Decides abrir 3 tiendas (3 clusters)\n",
    "2. **Centros iniciales**: Colocas temporalmente las tiendas en 3 ubicaciones al azar\n",
    "3. **Asignaci√≥n**: Cada cliente va a la tienda m√°s cercana a su casa\n",
    "4. **Recentrado**: Mueves cada tienda al centro geogr√°fico de sus clientes\n",
    "5. **Repetici√≥n**: Los clientes recalculan su tienda m√°s cercana y repites hasta que nadie cambie de tienda\n",
    "\n",
    "**K-means hace exactamente lo mismo, pero con pa√≠ses en un espacio de 75 dimensiones.**\n",
    "\n",
    "---\n",
    "\n",
    "### C√≥mo Funciona K-means (T√©cnico)\n",
    "\n",
    "#### Paso 1: Inicializaci√≥n\n",
    "- Selecciona K puntos aleatorios como \"centroides\" (centros de cluster)\n",
    "\n",
    "#### Paso 2: Asignaci√≥n\n",
    "- Calcula la distancia de cada pa√≠s a cada centroide\n",
    "- Asigna cada pa√≠s al centroide m√°s cercano\n",
    "\n",
    "#### Paso 3: Actualizaci√≥n\n",
    "- Recalcula la posici√≥n de cada centroide como el promedio de todos los pa√≠ses asignados a √©l\n",
    "\n",
    "#### Paso 4: Iteraci√≥n\n",
    "- Repite pasos 2 y 3 hasta que los centroides no se muevan (convergencia)\n",
    "\n",
    "---\n",
    "\n",
    "### Medida de Distancia: Euclidiana\n",
    "\n",
    "**Distancia Euclidiana** = La l√≠nea recta m√°s corta entre dos puntos.\n",
    "\n",
    "#### En 2D (f√°cil de visualizar):\n",
    "```\n",
    "Punto A = (1, 2)\n",
    "Punto B = (4, 6)\n",
    "Distancia = ‚àö[(4-1)¬≤ + (6-2)¬≤] = ‚àö[9 + 16] = 5\n",
    "```\n",
    "\n",
    "#### En 75D (nuestro caso):\n",
    "```\n",
    "Espa√±a = [2, 1, 0, 2, ..., 1]  (75 valores)\n",
    "Francia = [1, 2, 1, 2, ..., 0]  (75 valores)\n",
    "Distancia = ‚àö[suma de todas las diferencias al cuadrado]\n",
    "```\n",
    "\n",
    "**Interpretaci√≥n**: Pa√≠ses con distancia peque√±a son similares en sus pol√≠ticas de IA.\n",
    "\n",
    "---\n",
    "\n",
    "### Ventajas de K-means\n",
    "\n",
    "‚úÖ **R√°pido**: Muy eficiente incluso con miles de puntos  \n",
    "‚úÖ **Simple**: F√°cil de entender e implementar  \n",
    "‚úÖ **Escalable**: Funciona bien con muchas variables  \n",
    "‚úÖ **Resultados claros**: Cada pa√≠s pertenece a exactamente un cluster  \n",
    "\n",
    "### Limitaciones\n",
    "\n",
    "‚ö†Ô∏è **Depende de K**: Debes especificar cu√°ntos clusters quieres  \n",
    "‚ö†Ô∏è **Sensible a inicializaci√≥n**: Diferentes puntos iniciales pueden dar resultados ligeramente diferentes  \n",
    "‚ö†Ô∏è **Asume clusters esf√©ricos**: No funciona bien con formas irregulares  \n",
    "\n",
    "### Par√°metros Utilizados\n",
    "\n",
    "```python\n",
    "KMeans(\n",
    "    n_clusters=2,      # N√∫mero de clusters (determinado por an√°lisis)\n",
    "    random_state=42,   # Semilla para reproducibilidad\n",
    "    n_init=10          # Ejecutar 10 veces y elegir el mejor resultado\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59850d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Determinaci√≥n del N√∫mero √ìptimo de Clusters\n",
    "\n",
    "### El Problema\n",
    "\n",
    "K-means requiere que especifiquemos **K** (n√∫mero de clusters) **antes** de ejecutarlo. Pero, ¬øcu√°ntos clusters debemos crear?\n",
    "\n",
    "- ¬ø2 grupos? ¬ø5? ¬ø10?\n",
    "- Si elegimos mal, podr√≠amos tener grupos que no tienen sentido\n",
    "\n",
    "### Soluci√≥n: Usar M√©tricas de Evaluaci√≥n\n",
    "\n",
    "Probamos diferentes valores de K (de 2 a 10) y evaluamos la calidad de cada soluci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä M√©todo 1: M√©todo del Codo (Elbow Method)\n",
    "\n",
    "### Concepto: Inercia\n",
    "\n",
    "**Inercia** = Suma de las distancias al cuadrado de cada punto a su centroide m√°s cercano.\n",
    "\n",
    "- **Inercia alta**: Los puntos est√°n lejos de sus centroides ‚Üí clusters mal definidos\n",
    "- **Inercia baja**: Los puntos est√°n cerca de sus centroides ‚Üí clusters compactos\n",
    "\n",
    "### üéØ Analog√≠a\n",
    "\n",
    "Imagina que organizas una fiesta y debes agrupar a los invitados en mesas:\n",
    "- **Inercia** = ¬øQu√© tan lejos est√°n las personas del centro de su mesa?\n",
    "- Quieres que todos est√©n cerca del centro de su mesa (inercia baja)\n",
    "\n",
    "### El \"Codo\"\n",
    "\n",
    "```\n",
    "K=2:  Inercia = 5000  ‚¨áÔ∏è (mejora grande)\n",
    "K=3:  Inercia = 3000  ‚¨áÔ∏è (mejora grande) \n",
    "K=4:  Inercia = 2500  ‚¨áÔ∏è (mejora moderada) ‚Üê CODO\n",
    "K=5:  Inercia = 2300  ‚¨áÔ∏è (mejora peque√±a)\n",
    "K=6:  Inercia = 2200  ‚¨áÔ∏è (mejora peque√±a)\n",
    "```\n",
    "\n",
    "**Punto del codo**: Donde la mejora deja de ser significativa.\n",
    "\n",
    "### ‚ö†Ô∏è Limitaci√≥n\n",
    "\n",
    "La inercia **siempre disminuye** al aumentar K. En el extremo:\n",
    "- K = N (cada punto es su propio cluster) ‚Üí Inercia = 0\n",
    "\n",
    "Pero esto no es √∫til. Por eso buscamos el punto donde agregar m√°s clusters no mejora mucho.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä M√©todo 2: Coeficiente de Silueta (Silhouette Score)\n",
    "\n",
    "### Concepto\n",
    "\n",
    "El **Coeficiente de Silueta** mide qu√© tan bien est√° asignado cada punto a su cluster.\n",
    "\n",
    "### F√≥rmula (Simplificada)\n",
    "\n",
    "Para cada punto:\n",
    "```\n",
    "a = Distancia promedio a otros puntos en su mismo cluster\n",
    "b = Distancia promedio a puntos del cluster m√°s cercano\n",
    "\n",
    "Silueta = (b - a) / max(a, b)\n",
    "```\n",
    "\n",
    "### Interpretaci√≥n\n",
    "\n",
    "```\n",
    "+1: Punto muy bien asignado (lejos de otros clusters)\n",
    " 0: Punto en la frontera (equidistante entre clusters)\n",
    "-1: Punto mal asignado (m√°s cerca de otro cluster)\n",
    "```\n",
    "\n",
    "### üéØ Analog√≠a\n",
    "\n",
    "En la universidad, formas grupos de estudio:\n",
    "- **Silueta alta**: Tu grupo tiene intereses muy similares y muy diferentes de otros grupos\n",
    "- **Silueta baja**: Podr√≠as pertenecer a varios grupos porque todos tienen intereses parecidos\n",
    "- **Silueta negativa**: Est√°s en el grupo equivocado\n",
    "\n",
    "### Ventaja sobre el M√©todo del Codo\n",
    "\n",
    "‚úÖ **M√©trica √∫nica**: Un solo n√∫mero para comparar  \n",
    "‚úÖ **Considera separaci√≥n**: No solo compacidad, tambi√©n distancia entre clusters  \n",
    "‚úÖ **√ìptimo claro**: El K con mayor silueta suele ser el mejor  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Resultado en Nuestro An√°lisis\n",
    "\n",
    "Probamos K = 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "\n",
    "```\n",
    "K=2: Silueta = 0.XXX  ‚Üê M√ÅXIMO\n",
    "K=3: Silueta = 0.YYY\n",
    "K=4: Silueta = 0.ZZZ\n",
    "...\n",
    "```\n",
    "\n",
    "**Conclusi√≥n**: **K = 2** es el n√∫mero √≥ptimo de clusters.\n",
    "\n",
    "### Interpretaci√≥n\n",
    "\n",
    "Los pa√≠ses de la regi√≥n europea de la OMS se dividen naturalmente en **2 grandes grupos**:\n",
    "1. **Cluster 0**: Pa√≠ses con desarrollo irregular (mayor√≠a)\n",
    "2. **Cluster 1**: Pa√≠ses en transici√≥n avanzada (minor√≠a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef08902",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Reducci√≥n de Dimensionalidad con PCA\n",
    "\n",
    "### El Problema de \"Alta Dimensionalidad\"\n",
    "\n",
    "Nuestros datos tienen **75 dimensiones** (variables):\n",
    "- Los humanos solo podemos visualizar en 2D (plano) o 3D (espacio)\n",
    "- Es imposible hacer un gr√°fico con 75 ejes\n",
    "\n",
    "### La Soluci√≥n: PCA (Principal Component Analysis)\n",
    "\n",
    "**PCA** = An√°lisis de Componentes Principales\n",
    "\n",
    "T√©cnica que **comprime** datos de muchas dimensiones a pocas dimensiones, **conservando la mayor informaci√≥n posible**.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Analog√≠a: La Sombra\n",
    "\n",
    "Imagina una escultura 3D:\n",
    "- **Original**: Objeto tridimensional \n",
    "- **Sombra**: Proyecci√≥n bidimensional en la pared\n",
    "- La sombra pierde informaci√≥n (profundidad) pero conserva buena parte de la forma\n",
    "\n",
    "**PCA hace lo mismo**: Proyecta datos de 75D a 2D o 3D, perdiendo algo de informaci√≥n pero manteniendo lo esencial.\n",
    "\n",
    "---\n",
    "\n",
    "## C√≥mo Funciona PCA (Conceptual)\n",
    "\n",
    "### Paso 1: Encontrar Direcciones de M√°xima Variaci√≥n\n",
    "\n",
    "Imagina un conjunto de puntos en forma de \"cigarro\" en 3D:\n",
    "- **Componente Principal 1 (PC1)**: Direcci√≥n del eje largo (m√°xima variaci√≥n)\n",
    "- **Componente Principal 2 (PC2)**: Direcci√≥n perpendicular de segunda m√°xima variaci√≥n  \n",
    "- **Componente Principal 3 (PC3)**: Direcci√≥n perpendicular restante\n",
    "\n",
    "### Paso 2: Proyecci√≥n\n",
    "\n",
    "Proyecta todos los puntos sobre las nuevas direcciones (PCs).\n",
    "\n",
    "### Paso 3: Selecci√≥n\n",
    "\n",
    "Qu√©date solo con las primeras componentes (PC1, PC2) que explican la mayor parte de la variaci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Varianza Explicada\n",
    "\n",
    "### ¬øQu√© es la Varianza Explicada?\n",
    "\n",
    "Porcentaje de informaci√≥n original que conservan las componentes principales.\n",
    "\n",
    "### Ejemplo (Nuestro Caso)\n",
    "\n",
    "```\n",
    "PC1: 45% de la varianza\n",
    "PC2: 18% de la varianza\n",
    "PC3: 12% de la varianza\n",
    "----------------------------\n",
    "Total (3 PCs): 75% de la varianza\n",
    "```\n",
    "\n",
    "**Interpretaci√≥n**: Con solo 3 dimensiones (de 75 originales) conservamos el 75% de la informaci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## üé® Visualizaci√≥n\n",
    "\n",
    "### Gr√°fico 2D (PC1 vs PC2)\n",
    "\n",
    "- **Eje X (PC1)**: Primera componente principal (45% varianza)\n",
    "- **Eje Y (PC2)**: Segunda componente principal (18% varianza)\n",
    "- **Puntos**: Cada pa√≠s\n",
    "- **Colores**: Cluster asignado\n",
    "\n",
    "**¬øQu√© vemos?**\n",
    "- Pa√≠ses cercanos son similares en sus pol√≠ticas de IA\n",
    "- Los dos clusters est√°n claramente separados\n",
    "\n",
    "### Gr√°fico 3D (PC1 vs PC2 vs PC3)\n",
    "\n",
    "Similar al 2D pero a√±adiendo una tercera dimensi√≥n, permitiendo ver la separaci√≥n desde diferentes √°ngulos.\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas de PCA\n",
    "\n",
    "‚úÖ **Visualizaci√≥n**: Convierte datos complejos en gr√°ficos comprensibles  \n",
    "‚úÖ **Reducci√≥n de ruido**: Elimina variaciones irrelevantes  \n",
    "‚úÖ **Eficiencia**: Reduce carga computacional  \n",
    "‚úÖ **Interpretabilidad**: Las primeras PCs capturan los patrones principales  \n",
    "\n",
    "## Limitaciones de PCA\n",
    "\n",
    "‚ö†Ô∏è **P√©rdida de informaci√≥n**: No conserva el 100% de los datos originales  \n",
    "‚ö†Ô∏è **Dif√≠cil interpretaci√≥n**: Las PCs son combinaciones de variables originales  \n",
    "‚ö†Ô∏è **Linealidad**: Asume relaciones lineales entre variables  \n",
    "\n",
    "---\n",
    "\n",
    "## Aplicaci√≥n en Nuestro Proyecto\n",
    "\n",
    "```python\n",
    "# PCA a 2 dimensiones para gr√°fico 2D\n",
    "pca_2d = PCA(n_components=2)\n",
    "\n",
    "# PCA a 3 dimensiones para gr√°fico 3D\n",
    "pca_3d = PCA(n_components=3)\n",
    "```\n",
    "\n",
    "**Resultado**: Visualizaciones claras que muestran la separaci√≥n entre clusters de pa√≠ses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36734388",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Interpretaci√≥n de Resultados\n",
    "\n",
    "### Los Dos Clusters Identificados\n",
    "\n",
    "El an√°lisis identific√≥ **2 grupos naturales** de pa√≠ses:\n",
    "\n",
    "---\n",
    "\n",
    "## üîµ Cluster 0: Desarrollo Irregular\n",
    "\n",
    "### Caracter√≠sticas\n",
    "- **41 pa√≠ses** (77% del total)\n",
    "- **Puntaje promedio**: 39.0/100\n",
    "- **Tipolog√≠a**: ‚ö™ Desarrollo Irregular\n",
    "\n",
    "### Perfil por √Åreas\n",
    "```\n",
    "Estrategia:          23.5/100  ‚ö†Ô∏è Muy bajo\n",
    "Regulaci√≥n:          18.7/100  ‚ö†Ô∏è Muy bajo (√°rea m√°s d√©bil)\n",
    "Gobernanza de Datos: 55.1/100  ‚úÖ Moderado (fortaleza relativa)\n",
    "Aplicaciones:        48.4/100  ‚ö™ Moderado\n",
    "Capacidades:         49.0/100  ‚ö™ Moderado\n",
    "```\n",
    "\n",
    "### Interpretaci√≥n\n",
    "\n",
    "**Patr√≥n identificado**: Pa√≠ses con **fortalezas y debilidades dispersas**\n",
    "\n",
    "- ‚úÖ **√Årea fuerte**: Gobernanza de datos (existe infraestructura b√°sica)\n",
    "- ‚ö†Ô∏è **√Åreas d√©biles**: Estrategia y regulaci√≥n (falta marco pol√≠tico claro)\n",
    "- **Explicaci√≥n**: Estos pa√≠ses est√°n trabajando en aspectos t√©cnicos (datos, aplicaciones) pero carecen de marcos estrat√©gicos y regulatorios s√≥lidos\n",
    "\n",
    "### Pa√≠ses Incluidos\n",
    "```\n",
    "AND, ARM, AUT, AZE, BGR, BIH, BLR, CHE, CYP, CZE, DEU, DNK, \n",
    "FIN, GEO, GRC, HRV, HUN, IRL, ISL, ITA, KAZ, KGZ, LTU, LUX, \n",
    "LVA, MCO, MDA, MKD, MLT, MNE, POL, PRT, ROU, SMR, SRB, SVK, \n",
    "SVN, TJK, TKM, UKR, UZB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üü¢ Cluster 1: En Transici√≥n Avanzada\n",
    "\n",
    "### Caracter√≠sticas\n",
    "- **12 pa√≠ses** (23% del total)\n",
    "- **Puntaje promedio**: 65.5/100\n",
    "- **Tipolog√≠a**: üü° En Transici√≥n Avanzada\n",
    "\n",
    "### Perfil por √Åreas\n",
    "```\n",
    "Estrategia:          40.5/100  ‚ö™ Moderado (√°rea m√°s d√©bil)\n",
    "Regulaci√≥n:          58.6/100  ‚úÖ Bueno\n",
    "Gobernanza de Datos: 76.7/100  ‚úÖ Muy bueno\n",
    "Aplicaciones:        79.2/100  ‚úÖ Muy bueno (fortaleza principal)\n",
    "Capacidades:         72.5/100  ‚úÖ Bueno\n",
    "```\n",
    "\n",
    "### Interpretaci√≥n\n",
    "\n",
    "**Patr√≥n identificado**: Pa√≠ses con **desarrollo medio-alto en mayor√≠a de √°reas**\n",
    "\n",
    "- ‚úÖ **√Åreas fuertes**: Aplicaciones de IA (79.2) y Gobernanza de datos (76.7)\n",
    "- ‚ö™ **√Årea por mejorar**: Estrategia (40.5) - aunque mejor que Cluster 0\n",
    "- **Explicaci√≥n**: Estos pa√≠ses han avanzado significativamente en implementaci√≥n pr√°ctica y capacidades, pero a√∫n desarrollan sus marcos estrat√©gicos nacionales\n",
    "\n",
    "### Pa√≠ses Incluidos\n",
    "```\n",
    "ALB, BEL, ESP, EST, FRA, GBR, ISR, NLD, NOR, RUS, SWE, TUR\n",
    "```\n",
    "\n",
    "### Pa√≠ses Destacados\n",
    "- **Reino Unido (GBR)**, **Francia (FRA)**, **Pa√≠ses Bajos (NLD)**: Potencias en IA con ecosistemas avanzados\n",
    "- **Espa√±a (ESP)**, **Noruega (NOR)**, **Suecia (SWE)**: Inversi√≥n significativa en aplicaciones de salud digital\n",
    "- **Estonia (EST)**: L√≠der en digitalizaci√≥n gubernamental\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Comparaci√≥n Entre Clusters\n",
    "\n",
    "### Diferencias Clave\n",
    "\n",
    "| Aspecto | Cluster 0 | Cluster 1 | Diferencia |\n",
    "|---------|-----------|-----------|------------|\n",
    "| **Tama√±o** | 41 pa√≠ses | 12 pa√≠ses | 3.4√ó m√°s grande |\n",
    "| **Puntaje general** | 39.0/100 | 65.5/100 | +26.5 puntos |\n",
    "| **Estrategia** | 23.5 | 40.5 | +17.0 puntos |\n",
    "| **Regulaci√≥n** | 18.7 | 58.6 | +39.9 puntos ‚≠ê |\n",
    "| **Gobernanza** | 55.1 | 76.7 | +21.6 puntos |\n",
    "| **Aplicaciones** | 48.4 | 79.2 | +30.8 puntos ‚≠ê |\n",
    "| **Capacidades** | 49.0 | 72.5 | +23.5 puntos |\n",
    "\n",
    "### Observaciones Importantes\n",
    "\n",
    "1. **Mayor brecha en Regulaci√≥n y Aplicaciones** (+39.9 y +30.8 puntos)\n",
    "   - Cluster 1 tiene marcos regulatorios mucho m√°s desarrollados\n",
    "   - Cluster 1 implementa significativamente m√°s aplicaciones de IA\n",
    "\n",
    "2. **Menor brecha en Estrategia** (+17.0 puntos)\n",
    "   - Ambos clusters tienen margen de mejora en estrategias nacionales\n",
    "   - Sugiere que la estrategia formal no siempre precede a la implementaci√≥n\n",
    "\n",
    "3. **√Årea com√∫n fuerte: Gobernanza de Datos**\n",
    "   - Incluso Cluster 0 tiene puntuaci√≥n moderada (55.1)\n",
    "   - Refleja cumplimiento de normativas europeas (ej: GDPR)\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Insights Profundos\n",
    "\n",
    "### 1. Modelo de Desarrollo \"Bottom-Up\"\n",
    "\n",
    "**Observaci√≥n**: Cluster 1 tiene aplicaciones fuertes (79.2) pero estrategia moderada (40.5)\n",
    "\n",
    "**Interpretaci√≥n**: Muchos pa√≠ses avanzan **primero en implementaci√≥n pr√°ctica** y luego formalizan estrategias. \n",
    "\n",
    "**Implicaci√≥n**: La innovaci√≥n en salud digital puede ocurrir sin esperar marcos estrat√©gicos completos.\n",
    "\n",
    "### 2. Importancia del Marco Regulatorio\n",
    "\n",
    "**Observaci√≥n**: La regulaci√≥n es la mayor diferencia entre clusters (+39.9 puntos)\n",
    "\n",
    "**Interpretaci√≥n**: Un marco regulatorio s√≥lido es **clave para pasar de desarrollo irregular a transici√≥n avanzada**.\n",
    "\n",
    "**Implicaci√≥n**: Las pol√≠ticas regulatorias son un acelerador cr√≠tico de adopci√≥n de IA.\n",
    "\n",
    "### 3. Efecto del Contexto Europeo\n",
    "\n",
    "**Observaci√≥n**: Incluso Cluster 0 tiene gobernanza de datos aceptable (55.1)\n",
    "\n",
    "**Interpretaci√≥n**: La legislaci√≥n europea com√∫n (GDPR, etc.) eleva el est√°ndar m√≠nimo de todos los pa√≠ses.\n",
    "\n",
    "**Implicaci√≥n**: Los marcos supranacionales pueden homogeneizar ciertos aspectos de madurez digital."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1886f28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Conclusiones y Aplicaciones\n",
    "\n",
    "### Resumen del Proceso de ML\n",
    "\n",
    "```\n",
    "1. Preparaci√≥n de Datos\n",
    "   ‚îú‚îÄ Transformaci√≥n a formato ancho\n",
    "   ‚îú‚îÄ Codificaci√≥n categ√≥rica (YES=2, UD=1, NO=0)\n",
    "   ‚îî‚îÄ Imputaci√≥n de valores faltantes\n",
    "   \n",
    "2. Aplicaci√≥n de K-means\n",
    "   ‚îú‚îÄ Prueba de K=2 hasta K=10\n",
    "   ‚îú‚îÄ Evaluaci√≥n con m√©todo del codo\n",
    "   ‚îî‚îÄ Selecci√≥n √≥ptima con coeficiente de silueta\n",
    "   \n",
    "3. Visualizaci√≥n con PCA\n",
    "   ‚îú‚îÄ Reducci√≥n de 75D a 2D/3D\n",
    "   ‚îî‚îÄ Gr√°ficos interactivos de clusters\n",
    "   \n",
    "4. Interpretaci√≥n\n",
    "   ‚îú‚îÄ An√°lisis de perfiles por √°rea\n",
    "   ‚îú‚îÄ Identificaci√≥n de tipolog√≠as\n",
    "   ‚îî‚îÄ Extracci√≥n de insights\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Principales Hallazgos\n",
    "\n",
    "### Hallazgo 1: Dos Grupos Naturales\n",
    "\n",
    "Los pa√≠ses de la regi√≥n europea se dividen naturalmente en dos niveles de madurez en IA para salud:\n",
    "- **77% en etapa inicial/media** (Cluster 0)\n",
    "- **23% en etapa avanzada** (Cluster 1)\n",
    "\n",
    "### Hallazgo 2: Brecha en Regulaci√≥n\n",
    "\n",
    "La **regulaci√≥n** es el factor que m√°s diferencia los clusters (+39.9 puntos), sugiriendo que marcos legales son cr√≠ticos para avanzar.\n",
    "\n",
    "### Hallazgo 3: Estrategia No Es Prerequisito\n",
    "\n",
    "Pa√≠ses avanzados tienen **aplicaciones fuertes antes de estrategias completas**, indicando que la innovaci√≥n pr√°ctica puede preceder a la planificaci√≥n formal.\n",
    "\n",
    "### Hallazgo 4: Piso Com√∫n Europeo\n",
    "\n",
    "Incluso pa√≠ses en Cluster 0 tienen **gobernanza de datos moderada**, reflejando el impacto de regulaciones europeas comunes.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Aplicaciones Pr√°cticas\n",
    "\n",
    "### Para Gobiernos\n",
    "\n",
    "1. **Benchmarking**: Compararse con pa√≠ses de su mismo cluster\n",
    "2. **Priorizaci√≥n**: Identificar √°reas d√©biles espec√≠ficas de su tipolog√≠a\n",
    "3. **Aprendizaje**: Estudiar mejores pr√°cticas de pa√≠ses en Cluster 1\n",
    "4. **Roadmap**: Dise√±ar estrategias para transitar entre clusters\n",
    "\n",
    "### Para Investigadores\n",
    "\n",
    "1. **Estudios comparativos**: Analizar qu√© pol√≠ticas distinguen los clusters\n",
    "2. **Predicci√≥n**: Modelar trayectorias de desarrollo futuro\n",
    "3. **Causalidad**: Investigar factores que impulsan la transici√≥n\n",
    "\n",
    "### Para Organizaciones Internacionales (OMS)\n",
    "\n",
    "1. **Intervenciones dirigidas**: Dise√±ar programas espec√≠ficos por cluster\n",
    "2. **Asignaci√≥n de recursos**: Priorizar pa√≠ses seg√∫n necesidades de su tipolog√≠a\n",
    "3. **Monitoreo**: Rastrear movimientos entre clusters a lo largo del tiempo\n",
    "\n",
    "### Para Sector Privado\n",
    "\n",
    "1. **Estrategia de entrada**: Identificar mercados por nivel de madurez\n",
    "2. **Productos diferenciados**: Adaptar soluciones a cada tipolog√≠a\n",
    "3. **Partnerships**: Buscar colaboraciones con pa√≠ses en transici√≥n\n",
    "\n",
    "---\n",
    "\n",
    "## üîÆ Limitaciones y Consideraciones\n",
    "\n",
    "### Limitaciones T√©cnicas\n",
    "\n",
    "1. **Snapshot temporal**: Los datos representan un momento espec√≠fico (2024-2025)\n",
    "2. **Auto-reporte**: Basado en encuestas (posible sesgo de deseabilidad social)\n",
    "3. **Variables binarias**: La codificaci√≥n 0-1-2 simplifica realidades complejas\n",
    "4. **K=2 puede ser simplista**: Puede haber m√°s matices con m√°s clusters\n",
    "\n",
    "### Consideraciones Contextuales\n",
    "\n",
    "1. **Tama√±o econ√≥mico**: No considera PIB o recursos disponibles\n",
    "2. **Poblaci√≥n**: No ajusta por escala demogr√°fica\n",
    "3. **Historia**: No captura trayectorias hist√≥ricas\n",
    "4. **Cultura**: No refleja factores socioculturales\n",
    "\n",
    "### Validaci√≥n Futura\n",
    "\n",
    "- **An√°lisis longitudinal**: Repetir en a√±os futuros para validar estabilidad\n",
    "- **M√©todos alternativos**: Comparar con otros algoritmos (DBSCAN, clustering jer√°rquico)\n",
    "- **Variables adicionales**: Incorporar datos econ√≥micos, demogr√°ficos, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Valor del Machine Learning\n",
    "\n",
    "### Lo que ML nos permiti√≥ hacer\n",
    "\n",
    "‚úÖ **Objetividad**: Identificar grupos sin prejuicios previos  \n",
    "‚úÖ **Escala**: Procesar 75 variables √ó 53 pa√≠ses simult√°neamente  \n",
    "‚úÖ **Patrones ocultos**: Descubrir la brecha regulatoria como factor clave  \n",
    "‚úÖ **Visualizaci√≥n**: Convertir 75D en gr√°ficos comprensibles  \n",
    "‚úÖ **Reproducibilidad**: Resultados verificables y repetibles  \n",
    "\n",
    "### Lo que NO habr√≠amos visto manualmente\n",
    "\n",
    "‚ùå La magnitud exacta de la brecha regulatoria (+39.9 puntos)  \n",
    "‚ùå Que estrategia es √°rea d√©bil incluso en pa√≠ses avanzados  \n",
    "‚ùå La separaci√≥n natural en 2 grupos (no 3, 4 o 5)  \n",
    "‚ùå La homogeneidad en gobernanza de datos por GDPR  \n",
    "\n",
    "---\n",
    "\n",
    "## üìö Aprendizajes Clave\n",
    "\n",
    "### Sobre Machine Learning\n",
    "\n",
    "1. **No es magia**: Es matem√°tica aplicada con prop√≥sito claro\n",
    "2. **Requiere preparaci√≥n**: 80% del trabajo es preparar datos adecuadamente\n",
    "3. **M√∫ltiples t√©cnicas**: Combinar m√©todos (K-means + PCA) da mejores resultados\n",
    "4. **Interpretaci√≥n es cr√≠tica**: Los n√∫meros sin contexto no sirven\n",
    "\n",
    "### Sobre Clustering\n",
    "\n",
    "1. **K-means es poderoso pero simple**: Bueno para comenzar\n",
    "2. **La validaci√≥n es esencial**: Usar m√∫ltiples m√©tricas (Codo + Silueta)\n",
    "3. **Visualizaci√≥n ayuda**: PCA hace clusters tangibles\n",
    "4. **El conocimiento del dominio importa**: Las tipolog√≠as deben tener sentido pr√°ctico\n",
    "\n",
    "### Sobre Datos de Pol√≠ticas P√∫blicas\n",
    "\n",
    "1. **Los surveys tienen valor**: Aunque imperfectos, revelan patrones reales\n",
    "2. **Variables categ√≥ricas son manejables**: Con codificaci√≥n apropiada\n",
    "3. **El contexto geopol√≠tico importa**: Europa tiene un piso regulatorio com√∫n\n",
    "4. **Las brechas son oportunidades**: Identificarlas es el primer paso para cerrarlas\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "### An√°lisis Adicionales Posibles\n",
    "\n",
    "1. **Clustering jer√°rquico**: Ver si hay subclusters dentro de Cluster 0\n",
    "2. **An√°lisis de tiempo**: Comparar con datos de a√±os anteriores (si existen)\n",
    "3. **Variables externas**: Cruzar con PIB, gasto en salud, √≠ndices de digitalizaci√≥n\n",
    "4. **Modelos predictivos**: Intentar predecir qu√© pa√≠ses pasar√°n a Cluster 1\n",
    "\n",
    "### Recomendaciones para Mejorar el Modelo\n",
    "\n",
    "1. **Ponderaci√≥n de variables**: Dar m√°s peso a dimensiones cr√≠ticas\n",
    "2. **Clustering fuzzy**: Permitir membres√≠a parcial a m√∫ltiples clusters\n",
    "3. **Validaci√≥n con expertos**: Contrastar tipolog√≠as con conocimiento de dominio\n",
    "4. **An√°lisis de sensibilidad**: Probar distintas codificaciones y ver estabilidad\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Glosario de T√©rminos\n",
    "\n",
    "- **Clustering**: Agrupamiento autom√°tico de objetos similares\n",
    "- **K-means**: Algoritmo que divide datos en K grupos minimizando distancias internas\n",
    "- **Centroide**: Centro (promedio) de un cluster\n",
    "- **Inercia**: Suma de distancias al cuadrado dentro de clusters\n",
    "- **Coeficiente de Silueta**: M√©trica de calidad de clustering (-1 a +1)\n",
    "- **PCA**: T√©cnica de reducci√≥n de dimensionalidad\n",
    "- **Componente Principal**: Eje de m√°xima variaci√≥n en los datos\n",
    "- **Varianza Explicada**: Porcentaje de informaci√≥n conservada tras reducci√≥n\n",
    "- **Codificaci√≥n Ordinal**: Convertir categor√≠as en n√∫meros con orden\n",
    "- **Imputaci√≥n**: Rellenar valores faltantes con estimaciones\n",
    "- **Mediana**: Valor central en un conjunto ordenado de n√∫meros\n",
    "- **Distancia Euclidiana**: L√≠nea recta m√°s corta entre dos puntos\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Referencias y Recursos\n",
    "\n",
    "### Documentaci√≥n T√©cnica\n",
    "- Scikit-learn K-means: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "- Scikit-learn PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "- Coeficiente de Silueta: https://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient\n",
    "\n",
    "### Lecturas Recomendadas\n",
    "- \"Introduction to Statistical Learning\" - James, Witten, Hastie, Tibshirani\n",
    "- \"Pattern Recognition and Machine Learning\" - Christopher Bishop\n",
    "- Curso ML de Andrew Ng (Coursera)\n",
    "\n",
    "### Dataset Original\n",
    "- WHO AIRA Survey: https://gateway.euro.who.int/en/datasets/aira/\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Checklist de Comprensi√≥n\n",
    "\n",
    "Despu√©s de leer este notebook, deber√≠as poder:\n",
    "\n",
    "- [ ] Explicar qu√© es clustering y por qu√© es √∫til\n",
    "- [ ] Describir c√≥mo funciona K-means en t√©rminos simples\n",
    "- [ ] Entender por qu√© necesitamos codificar variables categ√≥ricas\n",
    "- [ ] Explicar el m√©todo del codo y coeficiente de silueta\n",
    "- [ ] Comprender el prop√≥sito de PCA\n",
    "- [ ] Interpretar las tipolog√≠as de pa√≠ses identificadas\n",
    "- [ ] Identificar las principales diferencias entre Cluster 0 y 1\n",
    "- [ ] Sugerir aplicaciones pr√°cticas de estos resultados\n",
    "- [ ] Reconocer limitaciones del an√°lisis\n",
    "- [ ] Proponer mejoras o an√°lisis adicionales\n",
    "\n",
    "---\n",
    "\n",
    "## üí¨ Preguntas Frecuentes\n",
    "\n",
    "### P: ¬øPor qu√© solo 2 clusters y no m√°s?\n",
    "**R**: El coeficiente de silueta indic√≥ que 2 es el n√∫mero √≥ptimo. M√°s clusters fragmentar√≠an innecesariamente grupos naturales.\n",
    "\n",
    "### P: ¬øLos clusters son permanentes?\n",
    "**R**: No, son una fotograf√≠a de 2024-2025. Los pa√≠ses pueden moverse entre clusters con el tiempo.\n",
    "\n",
    "### P: ¬øSe puede usar con otros tipos de datos?\n",
    "**R**: ¬°S√≠! Este mismo enfoque se puede aplicar a cualquier conjunto de datos con m√∫ltiples variables categ√≥ricas u ordinales.\n",
    "\n",
    "### P: ¬øQu√© pasa si un pa√≠s es diferente a todos?\n",
    "**R**: K-means forzar√° su asignaci√≥n al cluster m√°s cercano. Para outliers, otros m√©todos como DBSCAN son mejores.\n",
    "\n",
    "### P: ¬øEsto puede predecir el futuro?\n",
    "**R**: No directamente. Identifica el estado actual. Para predicci√≥n se necesitar√≠an datos hist√≥ricos y modelos de series temporales.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Notas Finales\n",
    "\n",
    "Este an√°lisis de Machine Learning demuestra c√≥mo t√©cnicas computacionales pueden:\n",
    "\n",
    "1. **Transformar datos complejos** en insights accionables\n",
    "2. **Revelar patrones ocultos** que el an√°lisis manual no detectar√≠a  \n",
    "3. **Apoyar decisiones de pol√≠tica p√∫blica** con evidencia objetiva\n",
    "4. **Facilitar comparaciones internacionales** de forma sistem√°tica\n",
    "\n",
    "El √©xito radica no solo en aplicar algoritmos, sino en:\n",
    "- **Preparar datos cuidadosamente**\n",
    "- **Elegir t√©cnicas apropiadas**\n",
    "- **Validar resultados rigurosamente**\n",
    "- **Interpretar con conocimiento del dominio**\n",
    "\n",
    "**Machine Learning es una herramienta, no una soluci√≥n m√°gica.** Su valor depende de c√≥mo se usa y se interpreta.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; padding: 20px; background-color: #f0f8ff; border-radius: 10px; margin-top: 30px;\">\n",
    "    <h3>üéâ ¬°Felicidades por completar esta explicaci√≥n!</h3>\n",
    "    <p>Ahora tienes una comprensi√≥n s√≥lida del proceso de Machine Learning aplicado en el an√°lisis de tipolog√≠as de pa√≠ses.</p>\n",
    "    <p><strong>¬øSiguiente paso?</strong> Aplicar estos conceptos en tu propio an√°lisis de datos.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
